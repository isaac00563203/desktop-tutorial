- 每当有人问我强化学习能否解决他们的问题时，我会说“不能”。而且我发现这个回答起码在70%的场合下是正确的。  -Alex Irpan

- 除少数情况外，特定领域的算法会比强化学习更有效。如果你入门强化学习是出于对它的热爱，这没问题，但当你想把自己的强化学习成果和其他方法相比较时，你要做好心理准备。

```
给你一个安慰。我之前在处理一系列强化学习问题时，要花50%的时间，也就是差不多6周重新建立策略梯度。那会儿我已经干这行很久了，还有一个GPU阵列可以用，而且还有一大帮关系很好的经验老道的专家朋友可以天天见面。 但我发现对于强化学习这个领域，自己从监督学习上学到的所有关于CNN的设计理论好像都没什么用。什么credit assignment、supervision bitrate，完全没有用武之地；什么ResNets、batchnorms、深层网络，完全没有话语权。 在监督学习里，如果我们想要实现什么，即使最后做的很糟糕，我们还是能总结一些非随机性的东西。但是强化学习不是这样的，如果函数设计错了，或者超参数没调好，那最后的结果可能比随机生成的都差。而且就是因为它是强化学习，即使一切条件都很完美，我们还会有30%的失败率。 简而言之，你的失败不是因为选了神经网络这条路，而是因为选了Deep RL这条不归路。
```